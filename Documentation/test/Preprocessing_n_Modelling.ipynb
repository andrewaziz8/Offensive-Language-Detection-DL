{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MMAI894 DL Project.ipynb","provenance":[],"collapsed_sections":["Ulz9bs0l6GD6","0Z8Iw3gotp87","MBkNrsGO6sfy","Au9HhhSu5dRE","2VXqKPJD5j9p","WMfH71jR5pVh","C5G7PC2i5snV"],"toc_visible":true,"mount_file_id":"1rpb-T4CAh78y7emBd946lLoXaW63xCcd","authorship_tag":"ABX9TyPWCDyy3l2QI6tEclUjbyyd"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5faba992517a4e09a2dc500a4cc40555":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8bb9e6a71eda4cc2a12605869b82904e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fb682286b9314293b6c5f921c1c750fd","IPY_MODEL_64696e78d1d946a8a621192852dad217"]}},"8bb9e6a71eda4cc2a12605869b82904e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fb682286b9314293b6c5f921c1c750fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1ac0e65cd5074b90b6f8de1bbc1b67fc","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b8d679127c3d43c081adb84bae364046"}},"64696e78d1d946a8a621192852dad217":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c88df66000ed4bb38889776e12777d1a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:01&lt;00:00, 361B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c766a9a3d488481abbf7952419ddccd9"}},"1ac0e65cd5074b90b6f8de1bbc1b67fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b8d679127c3d43c081adb84bae364046":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c88df66000ed4bb38889776e12777d1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c766a9a3d488481abbf7952419ddccd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"326ce13007e54b2c8596f32360ab236c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_33cdce01a14440489fc451b88321ee49","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6280f45d03a14a3db3a5d8a1050d258c","IPY_MODEL_7a3ef004127b4eb7ae25704b33bfea7e"]}},"33cdce01a14440489fc451b88321ee49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6280f45d03a14a3db3a5d8a1050d258c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3b9a9e6e6f3f4dc68731a2e232974a40","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cad2ddbcb53d45e7ad7476ceb37a92cf"}},"7a3ef004127b4eb7ae25704b33bfea7e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_319bc9c90b9f4736a8edbef59af309c3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 1.79MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4bee014cab2743029537a9db2d1ed319"}},"3b9a9e6e6f3f4dc68731a2e232974a40":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cad2ddbcb53d45e7ad7476ceb37a92cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"319bc9c90b9f4736a8edbef59af309c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4bee014cab2743029537a9db2d1ed319":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"124a5cd72f5c4b50aa8d661864390411":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e55d7ed8aae54c6c95dc7e00c2b2b116","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_45910e55cd9f4e179bc4840dad1a6deb","IPY_MODEL_b20c806f19684efba4a751ac77f179af"]}},"e55d7ed8aae54c6c95dc7e00c2b2b116":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"45910e55cd9f4e179bc4840dad1a6deb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7110e04f57234be18fa6f31e3eefe9c4","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1c2cd4161d8c40f494641e5df1db6253"}},"b20c806f19684efba4a751ac77f179af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_244c9a167f55430cac3396bc869261aa","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:00&lt;00:00, 469kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b15cf6396b10441bbe7701ca2a9d0543"}},"7110e04f57234be18fa6f31e3eefe9c4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1c2cd4161d8c40f494641e5df1db6253":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"244c9a167f55430cac3396bc869261aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b15cf6396b10441bbe7701ca2a9d0543":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4d875dc4fd6f43efa0286b676d2a4c09":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_07067a8800534419aa35bcc7b7de446f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b8f21684f6f542a7bd47c19434270f58","IPY_MODEL_10b2da05766d40b88cd3911133e4303d"]}},"07067a8800534419aa35bcc7b7de446f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b8f21684f6f542a7bd47c19434270f58":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f483d9a1beea4e12bd1aff063e13f458","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5359dcb045c24ef5884686e5e9d1d546"}},"10b2da05766d40b88cd3911133e4303d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_78cdf802f0e44b3e9629a8a944476ae7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 33.7B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fc9ab6eebc33449985a53bbedb3af1f9"}},"f483d9a1beea4e12bd1aff063e13f458":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5359dcb045c24ef5884686e5e9d1d546":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78cdf802f0e44b3e9629a8a944476ae7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fc9ab6eebc33449985a53bbedb3af1f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"CsM9ttU7t0eJ"},"source":["#Import Libraries"]},{"cell_type":"code","metadata":{"id":"U5-ilWPKiPZz"},"source":["!pip install transformers\n","# !pip install flair"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lKMylqz1fhEU","executionInfo":{"status":"ok","timestamp":1616695134804,"user_tz":240,"elapsed":9452,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}}},"source":["import tensorflow.keras as keras\n","import pandas as pd\n","\n","import numpy as np\n","from numpy import zeros\n","import tensorflow.keras as keras\n","from tensorflow.keras.layers import Dense, Input, Dropout, Embedding, Bidirectional, LSTM, GRU, Flatten, LayerNormalization, BatchNormalization\n","from tensorflow.keras.preprocessing.text import Tokenizer, one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras import regularizers\n","\n","from nltk.tokenize import TweetTokenizer\n","from transformers import AutoTokenizer, AutoModel\n","from transformers import DistilBertTokenizer, TFDistilBertModel\n","# from transformers import BertTokenizer, TFBertModel, TFGPT2Model, GPT2Tokenizer\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, recall_score\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","\n","import re"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"ecv1Ji0GDRlD"},"source":["print(help(BertTokenizer))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ulz9bs0l6GD6"},"source":["###Not Used at this time"]},{"cell_type":"code","metadata":{"id":"uFgs6BcT6FZV"},"source":["# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","# model = AutoModel.from_pretrained(\"bert-base-uncased\")\n","# from pandas_profiling import ProfileReport\n","\n","\n","# dbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","\n","# try: # this is only working on the 2nd try in colab :)\n","#   from transformers import DistilBertTokenizer, TFDistilBertModel\n","# except Exception as err: # so we catch the error and import it again\n","#   from transformers import DistilBertTokenizer, TFDistilBertModel\n","\n","# import flair\n","# from flair.embeddings import WordEmbeddings\n","# from flair.embeddings import ELMoEmbeddings\n","# from flair.embeddings import TransformerWordEmbeddings\n","# from flair.data import Sentence"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Z8Iw3gotp87"},"source":["##Explore Raw Data"]},{"cell_type":"code","metadata":{"id":"cGS3vKPpjIe7"},"source":["#load the data\n","raw_data_df = pd.read_csv('https://query.data.world/s/twuhmzuhvitwqqcjh5picrq3qykr4r')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CR1YNArvk69w","executionInfo":{"status":"ok","timestamp":1616513277966,"user_tz":240,"elapsed":8391,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}},"outputId":"9fc71d47-e8ac-4a47-9328-218670990aba"},"source":["raw_data_df['class'].unique()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 1, 0])"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"PnRCP4KlswAC"},"source":["class_weight = compute_class_weight('balanced', np.arange(3), raw_data_df['class'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pUlIvy2CtGLE","executionInfo":{"status":"ok","timestamp":1616513368843,"user_tz":240,"elapsed":502,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}},"outputId":"757f9264-3b6b-4a80-ffd8-9725c5a1a92a"},"source":["class_weight"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([5.77692308, 0.43048463, 1.98438626])"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"FP9tjMR_uCju"},"source":["class_wedight_dict = dict((w, i) for w, i in enumerate(class_weight))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"voxEXSakuHTH","executionInfo":{"status":"ok","timestamp":1616513643095,"user_tz":240,"elapsed":604,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}},"outputId":"de471355-1f19-48d4-fe4b-3fbf7ce120ef"},"source":["class_wedight_dict"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 5.776923076923077, 1: 0.43048462741010945, 2: 1.9843862599087196}"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"_WdKV0_pPIIm"},"source":["y_test = prepare_target(raw_data_df['class'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4YLNcnS0PNus","executionInfo":{"status":"ok","timestamp":1616505578693,"user_tz":240,"elapsed":277,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}},"outputId":"f6e95592-543e-4314-91c5-01c2adea9c05"},"source":["sum(y_test[:,1])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["19190.0"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"aaWrK8vBmC11","executionInfo":{"status":"ok","timestamp":1616453743202,"user_tz":240,"elapsed":253,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}},"outputId":"a0e66595-37ca-4c63-8c65-0f2203d8e6f1"},"source":["raw_data_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>count</th>\n","      <th>hate_speech</th>\n","      <th>offensive_language</th>\n","      <th>neither</th>\n","      <th>class</th>\n","      <th>tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  count  ...  class                                              tweet\n","0           0      3  ...      2  !!! RT @mayasolovely: As a woman you shouldn't...\n","1           1      3  ...      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n","2           2      3  ...      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n","3           3      3  ...      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n","4           4      6  ...      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n","\n","[5 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"WGzlOTXT3H2S"},"source":["test = clean_data(raw_df['tweet'][0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Q8UB07ca3b-x","executionInfo":{"status":"ok","timestamp":1616516074120,"user_tz":240,"elapsed":1298,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}},"outputId":"2912e233-c316-4fac-e03c-c303d51cf138"},"source":[""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"! <repeat> rt  <allcaps> <user> : as a woman you shouldn't complain about cleaning up your house . &amp ; as a man you should always take the trash out . <repeat>\""]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"ClRFqvKo0Fos"},"source":["tweeter = TweetTokenizer(strip_handles=True)\n","tweet_tokenized = tweet_tokenizer(raw_data_df['tweet'][0:5])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iosinjwJ1GLu","executionInfo":{"status":"ok","timestamp":1616453907647,"user_tz":240,"elapsed":388,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}},"outputId":"b81800e2-b54b-4793-f8b7-f28c50484415"},"source":["print(tweet_tokenized, '\\n', raw_data_df['tweet'][0:5])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[['!', '!', '!', 'RT', ':', 'As', 'a', 'woman', 'you', \"shouldn't\", 'complain', 'about', 'cleaning', 'up', 'your', 'house', '.', '&', 'as', 'a', 'man', 'you', 'should', 'always', 'take', 'the', 'trash', 'out', '...'], ['!', '!', '!', 'RT', ':', 'boy', 'dats', 'cold', '...', 'tyga', 'dwn', 'bad', 'for', 'cuffin', 'dat', 'hoe', 'in', 'the', '1st', 'place', '!', '!'], ['!', '!', '!', 'RT', 'Dawg', '!', '!', '!', 'RT', ':', 'You', 'ever', 'fuck', 'a', 'bitch', 'and', 'she', 'start', 'to', 'cry', '?', 'You', 'be', 'confused', 'as', 'shit'], ['!', '!', '!', 'RT', ':', 'she', 'look', 'like', 'a', 'tranny'], ['!', '!', '!', 'RT', ':', 'The', 'shit', 'you', 'hear', 'about', 'me', 'might', 'be', 'true', 'or', 'it', 'might', 'be', 'faker', 'than', 'the', 'bitch', 'who', 'told', 'it', 'to', 'ya', '\\ue011']] \n"," 0    !!! RT @mayasolovely: As a woman you shouldn't...\n","1    !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n","2    !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n","3    !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n","4    !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n","Name: tweet, dtype: object\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ak2yvaUNjNea"},"source":["flat_list = [item for sublist in tweet_tokenized for item in sublist]\n","a = np.unique(np.array(flat_list))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oTSrSRdiK-0y","executionInfo":{"status":"ok","timestamp":1616454143862,"user_tz":240,"elapsed":256,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}},"outputId":"725979e1-684e-4c4a-88db-45ce390d303b"},"source":["a.shape[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["68"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"_4pL1HpPSfPJ"},"source":["kt = Tokenizer()\n","kt.fit_on_texts(raw_data_df['tweet'][0:5])\n","word_index = kt.word_index"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ihKgF4kZXxy2","executionInfo":{"status":"ok","timestamp":1616453865255,"user_tz":240,"elapsed":270,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}},"outputId":"49db8a31-4de7-4a30-9644-c06c4fbeee00"},"source":["word_index.items()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_items([('rt', 1), ('you', 2), ('a', 3), ('the', 4), ('as', 5), ('be', 6), ('about', 7), ('bitch', 8), ('she', 9), ('to', 10), ('shit', 11), ('might', 12), ('it', 13), ('mayasolovely', 14), ('woman', 15), (\"shouldn't\", 16), ('complain', 17), ('cleaning', 18), ('up', 19), ('your', 20), ('house', 21), ('amp', 22), ('man', 23), ('should', 24), ('always', 25), ('take', 26), ('trash', 27), ('out', 28), ('mleew17', 29), ('boy', 30), ('dats', 31), ('cold', 32), ('tyga', 33), ('dwn', 34), ('bad', 35), ('for', 36), ('cuffin', 37), ('dat', 38), ('hoe', 39), ('in', 40), ('1st', 41), ('place', 42), ('urkindofbrand', 43), ('dawg', 44), ('80sbaby4life', 45), ('ever', 46), ('fuck', 47), ('and', 48), ('start', 49), ('cry', 50), ('confused', 51), ('c', 52), ('g', 53), ('anderson', 54), ('viva', 55), ('based', 56), ('look', 57), ('like', 58), ('tranny', 59), ('shenikaroberts', 60), ('hear', 61), ('me', 62), ('true', 63), ('or', 64), ('faker', 65), ('than', 66), ('who', 67), ('told', 68), ('ya', 69), ('57361', 70)])"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"FoL7YzsfB4iz"},"source":["tweet_tokenized = [tweeter.tokenize(l) for l in raw_data_df['tweet']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"So4AlxqUB_e8"},"source":["tdf = pd.DataFrame(tweet_tokenized)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4aBLRLEYWZIg"},"source":["np.unique(tdf.values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KEfEHZf-wG1A"},"source":["tv, wi = keras_tokenizer(raw_data_df['tweet'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rv1IlFr2wiTy"},"source":["print(tv[0], \"\\n\", raw_data_df['tweet'][0],\"\\n\", wi)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"93U4IBqDCzZM"},"source":["tt = tweet_tokenizer(raw_data_df['tweet'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vN5FCd-9TWnr","executionInfo":{"elapsed":392,"status":"ok","timestamp":1616372405705,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"},"user_tz":240},"outputId":"139b2bae-e218-49f2-9681-f061979a6efb"},"source":["raw_data_df['class']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0        2\n","1        1\n","2        1\n","3        1\n","4        1\n","        ..\n","24778    1\n","24779    2\n","24780    1\n","24781    1\n","24782    2\n","Name: class, Length: 24783, dtype: int64"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"uvcjdJZfTI8u"},"source":["target_test = prepare_target(raw_data_df['class'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K1cb2T63ThGt","executionInfo":{"elapsed":179,"status":"ok","timestamp":1616372531100,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"},"user_tz":240},"outputId":"40c1e7f2-387e-4ef3-def1-7fa52c91cd8b"},"source":["target_test.T"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., ..., 0., 0., 0.],\n","       [0., 1., 1., ..., 1., 1., 0.],\n","       [1., 0., 0., ..., 0., 0., 1.]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"jtSrDqujmO_k"},"source":["#Data Preparation"]},{"cell_type":"code","metadata":{"id":"Tc9rG8FxlMxI","executionInfo":{"status":"ok","timestamp":1616695134806,"user_tz":240,"elapsed":4999,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}}},"source":["#load data\n","def load_data():\n","  raw_data_df = pd.read_csv('https://query.data.world/s/twuhmzuhvitwqqcjh5picrq3qykr4r')\n","  return raw_data_df"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_MOK6JrU6bTj"},"source":["###Preprocessing "]},{"cell_type":"code","metadata":{"id":"QPsaBiBb6YaW","executionInfo":{"status":"ok","timestamp":1616690685385,"user_tz":240,"elapsed":233,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}}},"source":["###############################################################################################################\n","#clean data copied from https://www.kaggle.com/amackcrane/python-version-of-glove-twitter-preprocess-script\n","FLAGS = re.MULTILINE | re.DOTALL\n","def hashtag(text):\n","  text = text.group()\n","  hashtag_body = text[1:]\n","  if hashtag_body.isupper():\n","      result = \"<hashtag> {} <allcaps>\".format(hashtag_body.lower())\n","  else:\n","      result = \" \".join([\"<hashtag>\"] + re.split(r\"(?=[A-Z])\", hashtag_body, flags=FLAGS))\n","  return result\n","\n","def allcaps(text):\n","    text = text.group()\n","    return text.lower() + \" <allcaps> \" # amackcrane added trailing space\n","    # function so code less repetitive\n","\n","def clean_data(text):\n","  eyes = r\"[8:=;]\"\n","  nose = r\"['`\\-]?\"\n","  def re_sub(pattern, repl):\n","      return re.sub(pattern, repl, text, flags=FLAGS)\n","\n","  text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n","  text = re_sub(r\"@\\w+\", \"<user>\")\n","  text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n","  text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n","  text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n","  text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n","  text = re_sub(r\"/\",\" / \")\n","  text = re_sub(r\"<3\",\"<heart>\")\n","  text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n","  text = re_sub(r\"#\\w+\", hashtag)  # amackcrane edit\n","  text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n","  text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n","    \n","\n","  ## -- I just don't understand why the Ruby script adds <allcaps> to everything so I limited the selection.\n","  # text = re_sub(r\"([^a-z0-9()<>'`\\-]){2,}\", allcaps)\n","  #text = re_sub(r\"([A-Z]){2,}\", allcaps)  # moved below -amackcrane\n","\n","  # amackcrane additions\n","  text = re_sub(r\"([a-zA-Z<>()])([?!.:;,])\", r\"\\1 \\2\")\n","  text = re_sub(r\"\\(([a-zA-Z<>]+)\\)\", r\"( \\1 )\")\n","  text = re_sub(r\"  \", r\" \")\n","  text = re_sub(r\" ([A-Z]){2,} \", allcaps)\n","    \n","  return text.lower()\n","\n","def preprocessing_tweet(tweet):\n","  for t in tweet:\n","    t = clean_data(t)\n","  return tweet\n","###########################################################################################################"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"yLSXKyhG6h5v","executionInfo":{"status":"ok","timestamp":1616695177996,"user_tz":240,"elapsed":199,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}}},"source":["#split train val test\n","def split_data(cleantweet):\n","  trainX, tempX = train_test_split(cleantweet, test_size=0.4, random_state=42)\n","  valX, testX = train_test_split(tempX, test_size=0.5, random_state=42)\n","  return trainX, valX, testX\n","\n","#extract tweet and y\n","def extract_tweet_and_y(raw_data_df):\n","  tweet, target = raw_data_df['tweet'], raw_data_df['class']\n","  return tweet, target\n","\n","#tokenize and vectorize input using keras tokenizer\n","def keras_tokenizer(tweet_train, tweet_val, tweet_test, maxnumwords):\n","  # maxnumwords = 2000\n","  kt = Tokenizer()\n","  kt.fit_on_texts(tweet_train)\n","  word_index = kt.word_index\n","  vocab_size = len(word_index) + 1\n","\n","  train_vectors = kt.texts_to_sequences(tweet_train) #Converting text to a vector of word indexes\n","  val_vectors = kt.texts_to_sequences(tweet_val) #Converting text to a vector of word indexes\n","  test_vectors = kt.texts_to_sequences(tweet_test) #Converting text to a vector of word indexes\n","  \n","  train_padded = pad_sequences(train_vectors, maxlen=maxnumwords, padding='post')\n","  val_padded = pad_sequences(val_vectors, maxlen=maxnumwords, padding='post')\n","  test_padded = pad_sequences(test_vectors, maxlen=maxnumwords, padding='post')\n","\n","  return  train_padded, val_padded, test_padded, vocab_size, word_index\n","\n","#GloVe embeddings using Glove twiter 100D\n","def GloveTwitterEmbedding(vocab_size, word_index):\n","  \n","  #Glove Twitter 100d\n","  embedding_path = \"/content/drive/MyDrive/Colab Notebooks/GloVe Twitter 27B/glove.twitter.27B.100d.txt\"\n","  # max_features = 30000\n","  # get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n","  # embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n","  embedding_index = dict(\n","      (o.strip().split(\" \")[0], np.array(o.strip().split(\" \")[1:], dtype=\"float32\")\n","      ) for o in open(embedding_path)\n","      )\n","  # embedding matrix\n","  embedding_matrix = zeros((vocab_size, 100))\n","  # for word, i in enumerate(tweet_tokenized):\n","  for t , i in enumerate(word_index.items()):\n","    embedding_vector = embedding_index.get(t)\n","    if embedding_vector is not None:\n","      embedding_matrix[i] = embedding_vector\n","  \n","  return embedding_matrix\n","\n","# HuggingFace Transformers AutoTokenizer\n","def hf_auto_tokenizer(tweet, maxnumwords):\n","  \n","  autoTokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","  tweet_tokenized = autoTokenizer(tweet.tolist(), padding = 'max_length',\n","                                  truncation = True, max_length = maxnumwords, return_tensors='tf')\n","  input_ids = tweet_tokenized['input_ids']\n","  att_mask = tweet_tokenized['attention_mask']\n","  return input_ids, att_mask\n","\n","#HuggingFace GPT2 Tokenizer\n","def hf_GPT2_tokenizer(tweet, maxnumwords):\n","\n","  gpt2Tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","  tweet_tokenized = gpt2Tokenizer(tweet.tolist(), padding = 'max_length', truncation = True, max_length = maxnumwords, return_tensors='tf')\n","  input_ids = tweet_tokenized['input_ids']\n","  att_mask = tweet_tokenized['attention_mask']\n","  return input_ids, att_mask\n","\n","#one hot encode y\n","def prepare_target(raw_y):\n","  class_weight = compute_class_weight('balanced', np.arange(3), raw_y)\n","  class_weight_dict = dict((c,w) for c, w in enumerate(class_weight))\n","  target = to_categorical(raw_y)\n","  return np.array(target), class_weight_dict\n"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MBkNrsGO6sfy"},"source":["###Not Used"]},{"cell_type":"code","metadata":{"id":"7bcCJvqy6qKm"},"source":["# #GloVe embeddings DO NOT USE\n","# def GloveEmbeddingmodel2(tweet):\n","#   glove_embedding = WordEmbeddings('glove')\n","#   tweet_glove_embedding=[]\n","#   for t in tweet:\n","#     temp_embedding=[]\n","#     sentence = Sentence(t)\n","#     glove_embedding.embed(sentence)\n","#     for token in sentence:\n","#       temp_embedding.append(token.embedding)\n","#     tweet_glove_embedding.append(temp_embedding)\n","#   return tweet_glove_embedding\n","\n","\n","# #tokenizers\n","# def tweet_tokenizer(tweet):\n","#   tt = TweetTokenizer(strip_handles=True)\n","#   tweet_tokenized = [tt.tokenize(l) for l in tweet]\n","#   return tweet_tokenized\n","\n","#   tweet_tokenized = tweet_tokenizer(tweet)\n","#   tweet_tokenized_flatten = [item for sublist in tweet_tokenized for item in sublist]\n","#   tweet_tokenized_unique = np.unique(np.array(tweet_tokenized_flatten))\n","#   vocab_size = len(tweet_tokenized_unique)\n","\n","#doc2vec embeddings using traing data only\n","# def build_d2vmodel(tweet_tokenized):\n","#   #prepare training data in doc2vec format:\n","#   train_doc2vec = [TaggedDocument((f), tags=[str(i)]) for i, f in enumerate(tweet_tokenized)]\n","#   #Train a doc2vec model to learn tweet representations. Use only training data!!\n","#   D2V_model = Doc2Vec(vector_size=50, alpha=0.025, min_count=5, dm =1, epochs=100)\n","#   D2V_model.build_vocab(train_doc2vec)\n","#   D2V_model.train(train_doc2vec, total_examples=model.corpus_count, epochs=model.epochs)\n","#   D2V_model.save(\"d2v.model\")\n","\n","# #vectorize tweet using Doc2Vec\n","# def encod_tweet_d2v(tweet_tokenized):\n","#   #Infer the feature representation for training and test data using the trained model\n","#   model= Doc2Vec.load(\"d2v.model\")\n","#   #infer in multiple steps to get a stable representation. \n","#   tweet_vectors =  [model.infer_vector(list_of_tokens, steps=50) for list_of_tokens in tweet_tokenized]\n","\n","# #word 2 vec embeddings, \n","# def build_w2vmodel(tweet_tokenized):\n","#   pass\n","\n","# #one hot encode\n","# def one_hot_encode(text):\n","#   vocab_size = 100\n","#   max_length = 4\n","#   text_one_hot = [one_hot(t, vocab_size) for t in text]\n","#   return text_one_hot"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HwggEJVStUr1"},"source":["#Build Albert's Model & Transfer Learning Model"]},{"cell_type":"markdown","metadata":{"id":"Au9HhhSu5dRE"},"source":["###Albert Model: BiDirectional LSTM"]},{"cell_type":"code","metadata":{"id":"EbW7Xz4PXJxM","executionInfo":{"status":"ok","timestamp":1616693610711,"user_tz":240,"elapsed":386,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}}},"source":["def albert_model(param={}):\n","  #Bi Directional LSTM\n","  max_seq_len = param['Max Length']\n","  inputs = Input(shape = (max_seq_len,), dtype='int64', name='inputs')\n","\n","  vocab_size = param['Vocab Size']\n","\n","  embedding_trainable = True\n","  e = Embedding(vocab_size, 100, embeddings_initializer ='uniform', \n","                input_length=max_seq_len, trainable = embedding_trainable)\n","  \n","  embedding_matrix = param['Embedding Matrix']\n","  if embedding_matrix is not None:\n","    embedding_trainable = False\n","    e = Embedding(vocab_size, 100, embeddings_initializer ='uniform', input_length=max_seq_len,\n","                      weights = [embedding_matrix], trainable = embedding_trainable)\n","\n","  model = Sequential()\n","  model.add(inputs)\n","  model.add(e)\n","  model.add(Bidirectional(LSTM(100, return_sequences=True, dropout=param['dropout']), merge_mode='concat'))\n","  model.add(Bidirectional(LSTM(100, return_sequences=True, dropout=param['dropout']),merge_mode='concat'))\n","  model.add(Flatten())\n","  model.add(LayerNormalization())\n","  model.add(Dense(param['fist_layer'], activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n","  model.add(Dropout(param['dropout']))\n","  model.add(LayerNormalization())\n","  model.add(Dense(param['secon_layer'], activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n","  model.add(Dropout(param['dropout']))\n","  model.add(Dense(3, activation='softmax'))\n","\n","  model.summary()\n","  return model\n","\n","# input = Input(shape=(max_len,))\n","# model = Embedding(vocab_size,100,weights=[embedding_matrix],input_length=max_len)(input)\n","# model =  Bidirectional (LSTM (100,return_sequences=True,dropout=0.50),merge_mode='concat')(model)\n","# model = TimeDistributed(Dense(100,activation='relu'))(model)\n","# model = Flatten()(model)\n","# model = Dense(100,activation='relu')(model)\n","# output = Dense(3,activation='softmax')(model)\n","# model = Model(input,output)\n","# model.compile(loss='sparse_categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2VXqKPJD5j9p"},"source":["###Transfer Learning Models, Bert, DistilBert & GPT2\n","\n"]},{"cell_type":"code","metadata":{"id":"5ljDM1Mx4ybJ","executionInfo":{"status":"ok","timestamp":1616695183225,"user_tz":240,"elapsed":205,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}}},"source":["def tl_disbert_model(param={}):\n","  \n","  trainable = param['Trainable']\n","  max_seq_len = param['Max_length']\n","  inputs = Input(shape= (max_seq_len,), dtype ='int64', name='inputs')\n","  masks = Input(shape = (max_seq_len,), dtype='int64', name='masks')\n","\n","  disBert_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n","  disBert_model.trainable = param['Trainable']\n","\n","  disBert_output = disBert_model(inputs, attention_mask = masks)\n","  disBert_last_hidden = disBert_output.last_hidden_state\n","  disBert_CLS_output =  disBert_last_hidden [:,0,:]\n","  x = Flatten()(disBert_CLS_output)\n","  x = Dense(param['first_layer'], activation='relu')(x)\n","  x = Dropout(param['dropout'])(x)\n","  x = Dense(param['second_layer'], activation='relu')(x)\n","  x = Dropout(param['dropout'])(x)\n","\n","  probs = Dense(3, activation='softmax')(x)\n","\n","  model = keras.Model(inputs = [inputs, masks], outputs=probs)\n","  model.summary()\n","\n","  return model\n","\n","def tl_bert_model(param={}):\n","\n","  \n","  max_seq_len = param['Max_length']\n","  inputs = Input(shape= (max_seq_len,), dtype ='int64', name='inputs')\n","  masks = Input(shape = (max_seq_len,), dtype='int64', name='masks')\n","\n","  Bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n","  Bert_model.trainable = param['Trainable']\n","\n","  Bert_output = Bert_model_model(inputs, attention_mask = masks)\n","  Bert_last_hidden = Bert_output.last_hidden_state\n","  Bert_CLS_output =  Bert_last_hidden [:,0,:]\n","  x = Dense(param['first_layer'], activation='relu', kernel_regularizer=regularizers.l2(0.01) )(Bert_CLS_output)\n","  x = Dropout(param['dropout'])(x)\n","  x = Dense(param['second_layer'], activation='relu')(x)\n","  x = Dropout(param['dropout'])(x)\n","\n","  probs = Dense(3, activation='softmax')(x)\n","\n","  model = keras.Model(inputs = [inputs, masks], outputs=probs)\n","  model.summary()\n","  return model\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"n0ln5SPJPPY8","executionInfo":{"status":"ok","timestamp":1616695183344,"user_tz":240,"elapsed":305,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}}},"source":["def tl_gpt2_model(param={}):\n","  \n","  trainable = param['Trainable']\n","  max_seq_len = param['Max_length']\n","  inputs = Input(shape= (max_seq_len,), dtype ='int64', name='inputs')\n","  masks = Input(shape = (max_seq_len,), dtype='int64', name='masks')\n","\n","  gpt2_model = TFGPT2Model.from_pretrained('gpt2')\n","  gpt2_model.trainable = param['Trainable']\n","\n","  gpt2_output = gpt2_model(inputs, attention_mask = masks)\n","  gpt2_last_hidden = gpt2_output.last_hidden_state\n","  gpt2_CLS_output =  gpt2_last_hidden[:,0,:]\n","  x = Flatten()(gpt2_CLS_output)\n","  x = Dense(param['first_layer'], activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n","  x = Dropout(param['dropout'])(x)\n","  x = Dense(param['second_layer'], activation='relu')(x)\n","  x = Dropout(param['dropout'])(x)\n","\n","  probs = Dense(3, activation='softmax')(x)\n","\n","  model = keras.Model(inputs = [inputs, masks], outputs=probs)\n","  model.summary()\n","  return model"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WMfH71jR5pVh"},"source":["###Assemble_model"]},{"cell_type":"code","metadata":{"id":"sBM7kyEx42SM"},"source":["def tl_assemble_model():\n","  pass\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C5G7PC2i5snV"},"source":["###Train, Compile, Evaluate model method"]},{"cell_type":"code","metadata":{"id":"aBDE8C-j44Mv","executionInfo":{"status":"ok","timestamp":1616695147050,"user_tz":240,"elapsed":224,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}}},"source":["def train_model(model, tweet_train, y_train, tweet_val, y_val, batch_size, num_epochs, class_weight):\n","  \n","  es = keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode='min', verbose=1, patience=3)\n","  history = model.fit(\n","            tweet_train, y_train,\n","            batch_size=batch_size,\n","            epochs=num_epochs,\n","            verbose=1,\n","            validation_data=(tweet_val, y_val),\n","            class_weight = class_weight,\n","            callbacks=[es])\n","  return model, history\n","\n","def compile_model(model):\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', \n","                metrics=['accuracy', \n","                         keras.metrics.AUC(curve=\"ROC\", multi_label=True), \n","                         keras.metrics.AUC(curve=\"PR\", multi_label=True), \n","                         keras.metrics.Precision(),\n","                         keras.metrics.Recall()])\n","  return model\n","  \n","def evaluate_model(model, model_inputs_and_masks_test, y_test):\n","    # TODO: evaluate the model\n","    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n","    # HINT: for pr_auc: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html \n","\n","    probs = model(model_inputs_and_masks_test, training=False)\n","    print(probs)\n","    print(y_test)\n","\n","    eval_dict = {\n","        \"Hate\": {\n","            \"pr_auc\": average_precision_score(y_test[:, 0], probs[:, 0]), \"pr_auc_random_guess\": sum(y_test[:, 0])/(1.0*y_test.shape[0]), \n","            \"roc_auc\": roc_auc_score(y_test[:, 0], probs[:, 0]), \"roc_auc_random_guess\": 0.5, \n","            \"precision\": precision_score(y_test[:, 0], probs[:, 0] > 0.2),\n","            \"recall\": recall_score(y_test[:, 0], probs[:, 0] > 0.2)\n","        }, \n","        \"Offensive\": {\n","            \"pr_auc\": average_precision_score(y_test[:, 1], probs[:, 1]), \"pr_auc_random_guess\": sum(y_test[:, 1])/(1.0*y_test.shape[0]), \n","            \"roc_auc\": roc_auc_score(y_test[:, 1], probs[:, 1]), \"roc_auc_random_guess\": 0.5, \n","            \"precision\": precision_score(y_test[:, 1], probs[:, 1] > 0.2),\n","            \"recall\": recall_score(y_test[:, 1], probs[:, 1] > 0.2)\n","        }, \n","        \"Neither\": {\n","            \"pr_auc\": average_precision_score(y_test[:, 2], probs[:, 2]), \"pr_auc_random_guess\": sum(y_test[:, 2])/(1.0*y_test.shape[0]), \n","            \"roc_auc\": roc_auc_score(y_test[:, 2], probs[:,2]), \"roc_auc_random_guess\": 0.5, \n","            \"precision\": precision_score(y_test[:, 2], probs[:, 2] > 0.2),\n","            \"recall\": recall_score(y_test[:, 2], probs[:, 2] > 0.2)\n","        }\n","    }\n","    return eval_dict"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_A24xA_RIsts"},"source":["#Execution"]},{"cell_type":"markdown","metadata":{"id":"TA-AIpcu-11p"},"source":["###Load, Clean & Split Data"]},{"cell_type":"code","metadata":{"id":"GbtIFQJZIwYD","executionInfo":{"status":"ok","timestamp":1616695186811,"user_tz":240,"elapsed":511,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}}},"source":["raw_df = load_data()\n","\n","clean_df = raw_df\n","# clean_df['tweet'] = preprocessing_tweet(clean_df['tweet'])\n","\n","train_df, val_df, test_df = split_data(clean_df)\n","\n","X_train, y_train = extract_tweet_and_y(train_df)\n","X_val, y_val = extract_tweet_and_y(val_df)\n","X_test, y_test = extract_tweet_and_y(test_df)\n","\n","\n","y_raw, class_weight_raw = prepare_target(clean_df['class'])\n","y_train, class_weight_train = prepare_target(y_train)\n","y_val, class_weight_val = prepare_target(y_val)\n","y_test, class_weight_test = prepare_target(y_test)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zXKxrvIG-6ai"},"source":["###Tokenize and vectorize input"]},{"cell_type":"code","metadata":{"id":"goVkygwLOZM1","executionInfo":{"status":"ok","timestamp":1616691617956,"user_tz":240,"elapsed":34961,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}}},"source":["#Albert Model Tokenizer\n","X_train_albert, X_val_albert, X_test_albert, vocab_size, word_index = keras_tokenizer(X_train,X_val,X_test, maxnumwords=100)\n","\n","#Use GloVe Embedding\n","embedding_matrix = GloveTwitterEmbedding(vocab_size, word_index)"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"LtfBba_T_wNk","colab":{"base_uri":"https://localhost:8080/","height":215,"referenced_widgets":["5faba992517a4e09a2dc500a4cc40555","8bb9e6a71eda4cc2a12605869b82904e","fb682286b9314293b6c5f921c1c750fd","64696e78d1d946a8a621192852dad217","1ac0e65cd5074b90b6f8de1bbc1b67fc","b8d679127c3d43c081adb84bae364046","c88df66000ed4bb38889776e12777d1a","c766a9a3d488481abbf7952419ddccd9","326ce13007e54b2c8596f32360ab236c","33cdce01a14440489fc451b88321ee49","6280f45d03a14a3db3a5d8a1050d258c","7a3ef004127b4eb7ae25704b33bfea7e","3b9a9e6e6f3f4dc68731a2e232974a40","cad2ddbcb53d45e7ad7476ceb37a92cf","319bc9c90b9f4736a8edbef59af309c3","4bee014cab2743029537a9db2d1ed319","124a5cd72f5c4b50aa8d661864390411","e55d7ed8aae54c6c95dc7e00c2b2b116","45910e55cd9f4e179bc4840dad1a6deb","b20c806f19684efba4a751ac77f179af","7110e04f57234be18fa6f31e3eefe9c4","1c2cd4161d8c40f494641e5df1db6253","244c9a167f55430cac3396bc869261aa","b15cf6396b10441bbe7701ca2a9d0543","4d875dc4fd6f43efa0286b676d2a4c09","07067a8800534419aa35bcc7b7de446f","b8f21684f6f542a7bd47c19434270f58","10b2da05766d40b88cd3911133e4303d","f483d9a1beea4e12bd1aff063e13f458","5359dcb045c24ef5884686e5e9d1d546","78cdf802f0e44b3e9629a8a944476ae7","fc9ab6eebc33449985a53bbedb3af1f9"]},"executionInfo":{"status":"ok","timestamp":1616695299523,"user_tz":240,"elapsed":3052,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}},"outputId":"436b23f8-163e-407c-8441-44b3df8da4d4"},"source":["#Transformers Tokenizer\n","X_train_bert, Attention_mask_train = hf_auto_tokenizer(X_train, maxnumwords=60)\n","X_val_bert, Attention_mask_val = hf_auto_tokenizer(X_val, maxnumwords=60)\n","X_test_bert, Attention_mask_test = hf_auto_tokenizer(X_test, maxnumwords =60)\n","\n","\n","train_bert_inputs_and_masks = {\n","    'inputs' : X_train_bert,\n","    'masks' :  Attention_mask_train\n","}\n","\n","val_bert_inputs_and_masks = {\n","    'inputs' : X_val_bert,\n","    'masks' : Attention_mask_val\n","}\n","\n","test_bert_inputs_and_masks = {\n","    'inputs' : X_test_bert,\n","    'masks' : Attention_mask_test\n","}"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5faba992517a4e09a2dc500a4cc40555","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"326ce13007e54b2c8596f32360ab236c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"124a5cd72f5c4b50aa8d661864390411","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d875dc4fd6f43efa0286b676d2a4c09","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lYZBUxwQRrqd"},"source":["#GPT2 Tokenizer\n","X_train_gpt, Att_mask_train_gpt = hf_GPT2_tokenizer(X_train, maxnumwords=100)\n","X_val_gpt, Att_mask_val_gpt = hf_GPT2_tokenizer(X_val, maxnumwords=100)\n","X_test_gpt, Att_mask_test_gpt = hf_GPT2_tokenizer(X_test, maxnumwords =100)\n","\n","\n","train_gpt_inputs_and_masks = {\n","    'inputs' : X_train_gpt,\n","    'masks' :  Att_mask_train_gpt\n","}\n","\n","val_gpt_inputs_and_masks = {\n","    'inputs' : X_val_gpt,\n","    'masks' : Att_mask_val_gpt\n","}\n","\n","test_gpt_inputs_and_masks = {\n","    'inputs' : X_test_gpt,\n","    'masks' : Att_mask_test_gpt\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"na9r9WBT_VtU"},"source":["###Train Models"]},{"cell_type":"code","metadata":{"id":"JL-jslsmOTFc"},"source":["#Albert Model\n","Albertmodel = albert_model(param={'Max_length': 100,\n","                                  'Vocab Size': vocab_size,\n","                                  'Embedding Matrix': embedding_matrix,\n","                                  'dropout':0.50,\n","                                  'first_layer' : 128,\n","                                  'second_layer' : 64,\n","                                  })\n","Albertmodel = compile_model(Albertmodel)\n","\n","Albertmodel, history_Albert = train_model(Albertmodel, X_train_albert, y_train, X_val_albert, y_val, batch_size=128, num_epochs=50, class_weight=class_weight_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1jCbbL1PAvJa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616695347420,"user_tz":240,"elapsed":47175,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}},"outputId":"4a438a84-f235-4a26-f538-5dbca9031076"},"source":["DistilBertmodel = tl_disbert_model(param={'Max_length': 60, \n","                                             'Trainable' : False,\n","                                             'first_layer' : 128,\n","                                             'second_layer' : 64,\n","                                             'dropout' :0.50\n","                                             })\n","DistilBertmodel = compile_model(DistilBertmodel)\n","\n","DistilBertmodel, history_disbert =  train_model(DistilBertmodel, train_bert_inputs_and_masks, y_train, val_bert_inputs_and_masks, y_val, batch_size=128, num_epochs=1, class_weight=class_weight_train)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'vocab_transform', 'activation_13', 'vocab_layer_norm']\n","- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","inputs (InputLayer)             [(None, 60)]         0                                            \n","__________________________________________________________________________________________________\n","masks (InputLayer)              [(None, 60)]         0                                            \n","__________________________________________________________________________________________________\n","tf_distil_bert_model_1 (TFDisti TFBaseModelOutput(la 66362880    inputs[0][0]                     \n","                                                                 masks[0][0]                      \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_1 (Sli (None, 768)          0           tf_distil_bert_model_1[0][0]     \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 768)          0           tf.__operators__.getitem_1[0][0] \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 128)          98432       flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_40 (Dropout)            (None, 128)          0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 64)           8256        dropout_40[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_41 (Dropout)            (None, 64)           0           dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 3)            195         dropout_41[0][0]                 \n","==================================================================================================\n","Total params: 66,469,763\n","Trainable params: 106,883\n","Non-trainable params: 66,362,880\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","117/117 [==============================] - ETA: 0s - loss: 1.1015 - accuracy: 0.4253 - auc_2: 0.5771 - auc_3: 0.3809 - precision_1: 0.5107 - recall_1: 0.1394WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","117/117 [==============================] - 45s 335ms/step - loss: 1.1009 - accuracy: 0.4258 - auc_2: 0.5777 - auc_3: 0.3814 - precision_1: 0.5116 - recall_1: 0.1398 - val_loss: 0.7872 - val_accuracy: 0.7902 - val_auc_2: 0.7817 - val_auc_3: 0.5805 - val_precision_1: 0.8819 - val_recall_1: 0.4821\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3hEFGKGvE6qx"},"source":["Bertmodel = tl_bert_model(param={'Max Length': 100,\n","                                  'Trainable' : False,\n","                                  'first_layer' : 128,\n","                                  'second_layer' : 64,\n","                                  'dropout' :0.50\n","                                 })\n","\n","Bertmodel = compile_model(Bertmodel)\n","\n","Bertmodel, history_bert = train_model(Bertmodel, train_bert_inputs_and_masks, y_train, val_bert_inputs_and_masks, y_val, batch_size=128, num_epochs=50, class_weight=class_weight_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1u90cc56SZ60"},"source":["gpt2model = tl_gpt2_model(param={'Max_length': 100,\n","                                  'Trainable' : False,\n","                                  'first_layer' : 128,\n","                                  'second_layer' : 64,\n","                                  'dropout' :0.50\n","                                 })\n","\n","gpt2model = compile_model(gpt2model)\n","\n","gpt2model, history_bert = train_model(gpt2model, train_gpt_inputs_and_masks, y_train, val_gpt_inputs_and_masks, y_val, batch_size=128, num_epochs=50, class_weight=class_weight_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HegXMjWYFg8m"},"source":["#Assemble model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g-eHcrf0_fcA"},"source":["###Evaluation and Compare Model Performance"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tGOwJxA-mTFa","executionInfo":{"status":"ok","timestamp":1616696138790,"user_tz":240,"elapsed":251,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}},"outputId":"0bb2ae69-0231-4b5f-986f-5f1f30dde2a2"},"source":["test_bert_inputs_and_masks['inputs']"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(4957, 60), dtype=int32, numpy=\n","array([[  101,  1045,  1005, ...,     0,     0,     0],\n","       [  101,  7570,  2229, ...,     0,     0,     0],\n","       [  101, 19387,  1030, ...,     0,     0,     0],\n","       ...,\n","       [  101, 19387,  1030, ...,     0,     0,     0],\n","       [  101, 19387,  1030, ...,     0,     0,     0],\n","       [  101,  1030,  2611, ...,     0,     0,     0]], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"-QHmnrqYkT65","executionInfo":{"status":"ok","timestamp":1616696044365,"user_tz":240,"elapsed":198,"user":{"displayName":"Jason Li","photoUrl":"https://lh3.googleusercontent.com/-MXuDo0MvoGw/AAAAAAAAAAI/AAAAAAAAAGI/xypEP-pcHVg/s64/photo.jpg","userId":"04045095967198645117"}}},"source":["test = {'inputs':test_bert_inputs_and_masks['inputs'][0:200], 'masks': test_bert_inputs_and_masks['masks'][0:200]}"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jv71O6n-XAEA"},"source":["eval_dict = evaluate_model(DistilBertmodel, test, y_test[0:200])\n","eval_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QAITYy54cJuM"},"source":["DistilBertmodel(test_bert_inputs_and_masks, training=False)"],"execution_count":null,"outputs":[]}]}